<tei>
    <teiHeader>
        <fileDesc xml:id="_228815645220.pdf"/>
    </teiHeader>
    <text xml:lang="en">


        <figure>

            <figDesc>Introduction 1<lb/> Certains domaines associés aux thèmes discutés ici échappent à mes compétences, comme<lb/> par exemple l&apos;évaluation des risques et des défauts de sûreté dans les transports. Ce qui<lb/> m&apos;a convaincu de l&apos;importance de ce sujet, ce sont quelques conclusions très générales, je<lb/> dirais volontiers quelques impressions que m&apos;inspire depuis quelques années l&apos;évolution très<lb/> remarquable de nos pouvoirs d&apos;analyse sur les processus de prise de décision en matière de<lb/> risque.<lb/> Le mot insécurité visera souvent ici la gestion des risques liés à des actes de malveillance<lb/> intentionnelle 2. . Les coûts de la sécurité prise en ce sens constituent aujourd&apos;hui une<lb/> composante de tout budget transport. Outre les coûts de prévention et de surveillance, les<lb/> coûts de prévision, il faut aussi envisager désormais le coût des dommages potentiels liés à<lb/> de tels actes.<lb/> Les événements du 11 septembre 2001, qui ont accéléré cette évolution, doivent suffire à<lb/> nous convaincre que les conséquences de tels dommages sont désormais commensurables<lb/> avec les coûts des guerres. On a pu ainsi remettre en cause l&apos;idée d&apos;une solution de<lb/> continuité entre les échelles de ces deux types de phénomènes. On parle en effet<lb/> aujourd&apos;hui, pour des guerres liées au terrorisme, d&apos;un ordre de grandeur qui semble bien<lb/> dépasser les milliers de milliards de dollars. C&apos;est le sens de la réaction du général Haig<lb/> (2003) : le terrorisme fait désormais partie de la guerre. Il s&apos;agit, en un sens que nous aurons<lb/> à préciser, de décisions stratégiques : les critères qui ont, aux yeux du gouvernement<lb/> américain, associé cet attentat aux guerres qui l&apos;ont suivi sont en effet davantage liés à la<lb/> 1. Je voudrais remercier Serge Pahaut, pour les discussions nombreuses et fructueuses que</figDesc>
        </figure>


        <figure>

            <figDesc>Histoire et théorie de la décision<lb/> « Entre ma passion pour l&apos;histoire et celle pour la modélisation mathématique,<lb/> je n&apos;avais pas à trancher.<lb/> La science économique pouvait les satisfaire toutes les deux. »<lb/> Lesourne, 2000, p. 189-190.<lb/> Etre sensible à ce qu&apos;on risque de perdre, voire à ce que l&apos;on perd déjà, justement parce que<lb/> l&apos;on a trop longtemps considéré cette perte comme négligeable, et être capable de refaire<lb/> son calcul, voilà donc un impératif qui nous apparaît aujourd&apos;hui, et auquel l&apos;économiste est<lb/> professionnellement familier. Pour comprendre ce que cet impératif présente de neuf pour un<lb/> certain nombre d&apos;acteurs engagés dans la bataille des affaires ou dans celle de la politique,<lb/> je me propose de vous présenter un bref rappel de quelques acquis récents de la théorie du<lb/> risque.<lb/> Le calcul des dommages liés à des événements soumis à telle ou telle distribution de<lb/> probabilités pose des problèmes dont la formulation a évolué au cours des dernières<lb/> décennies. On propose ici quelques brèves remarques sur certains aspects de cette<lb/> évolution des idées. La décision d&apos;allocation de ressources en environnement risqué obéit,<lb/> en termes modernes, au modèle théorique dit de l&apos;utilité espérée. Je donne ici un bref rappel<lb/> de l&apos;histoire de nos idées en la matière, dont on verra, j&apos;espère, qu&apos;il n&apos;est pas étranger à<lb/> notre discussion.<lb/> Le modèle théorique de l&apos;utilité espérée, esquissé par la famille Bernoulli au début du 18 ème<lb/> siècle, et formalisé voici un demi-siècle par von Neumann et Morgenstern (1944), corrigeait<lb/> le rationalisme classique de l&apos;application optimale des probabilités à la décision, qui inspirait<lb/> la correspondance de Pascal et Fermat au milieu du 17 ème siècle, dans laquelle ils se<lb/> contentaient de rationaliser la décision en fonction de la seule valeur espérée des bénéfices<lb/> associés à un ensemble d&apos;événements munis chacun d&apos;une probabilité donnée.<lb/> Reprenons quelque hauteur. Pour simplifier, prenons d&apos;abord le cas idéal d&apos;un monde sans<lb/> aléa. Si l&apos;évolution future d&apos;une économie est certaine, elle est unique, et les acteurs la<lb/> connaissent sans coup férir puisqu&apos;elle se déduit sans erreur de l&apos;état présent des choses.<lb/> Les revenus générés par les investissements sont connus, il n&apos;y a donc ici pas de risque, pas<lb/> de prime de risque, pas de spéculation et pas d&apos;assurance. Or, nous savons que même<lb/> Robinson ne vivait pas dans cette économie-là. Les entreprises, les contrats, les institutions<lb/> et le marché ne peuvent interagir que dans un univers où figurent, au minimum, le hasard et<lb/> sa prise en compte, le calcul du risque. Si le hasard est pris en compte, c&apos;est que des<lb/> événements possibles et leurs conséquences ne sont pas exclus, même si l&apos;on mène des<lb/> politiques visant à les exclure ou à les gérer.<lb/> Reprenons quelques étapes critiques de cette évolution de la prise en compte de l&apos;évaluation<lb/> des possibles. Pour les auteurs qui inaugurent le calcul des probabilités, Huygens et Bernoulli avec Pascal et Fermat, les événements futurs sont inconnus mais non pas leurs<lb/> probabilités 6 .<lb/> Tout est-il dit ? Suffira-t-il désormais d&apos;ajouter des résultats de détail à cette loi générale ?<lb/> Non. Un contre-exemple énoncé par l&apos;un des protagonistes majeurs de la construction du<lb/> calcul des probabilités, montrera très vite que la rationalité de ces calculs n&apos;est pas toujours<lb/> recommandable. C&apos;est le paradoxe de Saint-Pétersbourg, construit pour montrer que si un<lb/> gain infini sur le très long terme doit selon la théorie de la valeur espérée inciter le joueur à<lb/> miser une somme infinie, on observe —et on comprend— qu&apos;un joueur raisonnable évitera<lb/> les extrêmes auxquels conduit cette décision rationaliste, et misera en fait, raisonnablement,<lb/> une somme relativement faible. En présentant ce paradoxe, le « neveu Bernoulli », Nicolas,<lb/> remarque ainsi, dès le début du 18 ème siècle, que si l&apos;on retenait le seul critère de cette valeur<lb/> espérée des gains, comme le faisaient les probabilistes du 17 ème siècle, il serait inévitable de<lb/> recommander des choix qu&apos;aucune personne raisonnable ne prendrait en pratique.<lb/> Les conclusions de Bernoulli valent plus encore que son paradoxe. Il conclut, en effet, qu&apos;il<lb/> faudra introduire une nouvelle notion, celle de l&apos;utilité espérée. Il ouvre ainsi un nouveau<lb/> domaine en avançant qu&apos;aucune estimation du risque ne peut négliger le problème inverse :<lb/> quel est le gain requis pout procurer à une personne donnée une utilité dont il est à peine<lb/> possible de dire quelque chose de certain, tant elle peut changer selon les circonstances.<lb/> « Ainsi, » poursuit-il (1738), « quoique le plus souvent un pauvre se réjouira plus qu&apos;un riche<lb/> d&apos;une même somme, cependant et par exemple, il est concevable qu&apos;un prisonnier riche,<lb/> mettons de deux mille ducats, à qui on réclame encore le même montant pour prix de sa<lb/> liberté, donnera plus d&apos;importance à un gain de deux mille ducats qu&apos;un autre homme qui a<lb/> moins d&apos;argent que lui. »<lb/> Les modèles de l&apos;utilité espérée prendront donc en compte l&apos;attitude du décideur à travers<lb/> une fonction d&apos;utilité U ayant pour seul argument la richesse ou les gains du décideur. On a<lb/> bien sûr critiqué les énoncés de Bernoulli. Il demeure qu&apos;il nous a ouvert un nouveau monde<lb/> (Meusnier, 2005). En un sens, ses intuitions sont aujourd&apos;hui plus vraies que quand il leur<lb/> donnait forme ; la concavité de la fonction d&apos;utilité deviendra chez les modernes à la fin du<lb/> 20 ème siècle l&apos;expression de l&apos;aversion au risque, et elle sera d&apos;autant plus prononcée que<lb/> cette aversion est forte. Je me permets d&apos;attirer votre attention sur l&apos;extrême généralité du<lb/> raisonnement. Cette lecture des perceptions, correspondant à une valorisation décroissante<lb/> des unités marginales successives, a permis de construire une des premières fonctions<lb/> mathématiques du comportement d&apos;évaluation, et d&apos;introduire des procédures<lb/> expérimentales dans de nombreuses disciplines.<lb/> On me permettra de mentionner ici la théorie économique des rendements décroissants en<lb/> fonction d&apos;incréments d&apos;investissement ou encore la théorie physiologique de la perception<lb/> en fonction d&apos;incréments de valeurs d&apos;une donnée accessible à la sensation. Ces domaines,<lb/> très divers, ont imposé des mises au point sévères pour éviter de déboucher sur une<lb/> périlleuse «theory for everything ». Mais nous sommes ici devant une des portes qui ont<lb/> permis aux chercheurs du 19 ème siècle d&apos;entrer dans le Nouveau Monde des sciences<lb/> humaines. Il n&apos;est pas anachronique de lire sur la courbe classique la typologie des attitudes<lb/> des acteurs face au risque. Un individu qui tolère moins le risque qu&apos;un autre construit sa<lb/> fonction d&apos;utilité comme une transformation concave de la fonction d&apos;utilité de celui-ci. On envisage le cas d&apos;individus dont l&apos;aversion au risque est nulle : leur fonction d&apos;utilité sera<lb/> linéaire ; et d&apos;autres qui aiment le risque : la négativité de leur aversion au risque se traduira<lb/> par une fonction d&apos;utilité convexe.</figDesc>
        </figure>


        <figure>

            <head>Figure</head>

            <label>1</label>

            <head>. </head>
 
            <figDesc>L&apos;utilité U comme fonction concave des gains g (Bernoulli 1738).<lb/> La théorie de l&apos;utilité espérée a sans aucun doute constitué le paradigme dominant de la<lb/> théorie de la décision depuis le milieu du siècle dernier. On a pu dire, en simplifiant<lb/> beaucoup, que jusqu&apos;aux années 1980 elle a fourni un cadre de référence souvent discuté,<lb/> mais toujours retenu, pour la prédiction en économie et en finance, pour la prescription en<lb/> sciences de la gestion, et pour la description en psychologie. Disons tout de suite que le but, selon les auteurs eux-mêmes, n&apos;est pas de mieux décrire le<lb/> comportement de l&apos;assureur ou du banquier. Les modèles construits par Kahneman et<lb/> Tversky (1979) tentent tout au plus de mieux rendre compte de certaines caractéristiques de<lb/> décisions relativement simples et isolées. Ceci impose de sévères limites à la portée<lb/> descriptive qu&apos;on voudrait leur prêter s&apos;agissant du monde réel. Enfin et surtout —et ceci<lb/> réduit d&apos;autant le pouvoir prédictif de la théorie— dans le monde réel, ainsi que Kahneman a<lb/> tenu à le montrer, il arrive souvent que les gens prennent des risques parce qu&apos;ils ne savent<lb/> pas qu&apos;ils en prennent. Il ne faut donc certes pas demander à la théorie des perspectives de<lb/> donner des réponses directes aux questions pratiques que se posent les décideurs du<lb/> monde réel.<lb/> De nombreux travaux d&apos;observation menés au cours des dernières décennies ont permis de<lb/> montrer des déviations au comportement prédit par la théorie de l&apos;utilité espérée. L&apos;aversion<lb/> au risque mise en oeuvre par les décideurs s&apos;avère plus complexe dans la pratique ; elle est<lb/> de plus liée à une nouvelle aversion, l&apos;aversion aux pertes, et prend en compte les<lb/> conséquences d&apos;une séquence de gains et de pertes.<lb/> Il peut être utile de présenter brièvement la déformation des probabilités de Kahneman et<lb/> Tversky : les événements qui se présentent avec une probabilité très faible, voisine de zéro,<lb/> sont subjectivement perçus comme dotés d&apos;une probabilité plus forte (phénomène de<lb/> surestimation), tandis que ceux qui se produisent avec une probabilité très forte, voisine de<lb/> un, sont subjectivement perçus comme dotés d&apos;une probabilité plus faible (phénomène de<lb/> sous-estimation). Ainsi, dans la description du comportement d&apos;un décideur face à la loterie<lb/> (x, p), on remplace les probabilités objectives p par des probabilités déformées à travers une<lb/> fonction de transformation des probabilités w(.), strictement croissante sur l&apos;intervalle [0,1]<lb/> avec w(0)=0 et w(1)=1. Au lieu d&apos;évaluer la loterie (x, p) par p U(x), on utilise l&apos;évaluation<lb/> w(p) U(x), où U(.) représente la fonction d&apos;utilité de l&apos;individu.</figDesc>
        </figure>


        <figure>

            <head>Figure</head>

            <label>2</label>

            <head>. </head>
 
            <figDesc>Déformation des probabilités : probabilités objectives w comme transformation des<lb/> probabilités subjectives p (Tversky et Kahneman 1992).<lb/> Tversky et Kahneman (1992) ont par la suite généralisé la théorie des prospects en<lb/> constatant que la façon dont les individus ont tendance à déformer la probabilité d&apos;un<lb/> événement dépend de la position de cet événement sur une échelle classant les<lb/> événements du plus au moins favorable. L&apos;individu raisonne alors sur les probabilités<lb/> cumulées d&apos;obtenir au moins une somme donnée. Ainsi, comme le montre la figure ci-dessus, si la probabilité d&apos;obtenir au moins 1 vaut en réalité q=15%, un individu estimera, par<lb/> exemple, cette probabilité à w(q)=35%. Si, par ailleurs, la probabilité d&apos;obtenir au moins 2<lb/> vaut en réalité p+q=50%, l&apos;individus estimera cette probabilité à w(p+q)=45%. La probablité<lb/> d&apos;obtenir entre 1 et 2 sera alors déformée de p=35% à w(p+q)-w(q)=10%.<lb/> La courbe présentée ici donne un relevé des transformations des univers du risque liées à ce<lb/> que l&apos;on appelle depuis la série inaugurale de Simon (1982) la rationalité limitée. Pour ce<lb/> faire une fonction d&apos;utilité plus complexe est introduite ; elle prend en compte d&apos;autres<lb/> déformations liées à l&apos;évaluation subjective. On a d&apos;abord une dissymétrie entre perception<lb/> des gains et des pertes ; on voit tout de suite qu&apos;il s&apos;agit ici d&apos;une fonction d&apos;utilité concave<lb/> pour les gains et convexe pour les pertes. On retrouve une loi de sensibilité décroissante :<lb/> plus on s&apos;éloigne du point de référence, plus l&apos;impact subjectif est faible. Enfin, les désutilités<lb/> marginales liées aux pertes sont plus fortes que les utilités marginales de variations de gains<lb/> de même grandeur.</figDesc>
        </figure>


        <figure>

            <head>Figure</head>

            <label>3</label>

            <head>. </head>
 
            <figDesc>Déformation des gains et des pertes: évaluation subjective E comme fonction des<lb/> revenus objectifs, où l&apos;on distingue les domaines des gains g et des pertes p (Tversky et<lb/> Kahneman 1992). Le point de référence est ici en (0, 0).</figDesc>
        </figure>


        <figure>

            <figDesc>L&apos;approche expérimentale de la perception des risques : bref aperçu<lb/> On propose ici quelques remarques sur certains aspects des rapports entre gestion de<lb/> sécurité, perception des risques et analyse coût-bénéfice. La psychologie et l&apos;économie<lb/> expérimentales ont mis en évidence des déviations systématiques des comportements<lb/> d&apos;individus confrontés à des situations de risque où de nombreuses approches traditionnelles<lb/> proposent des prédictions liées à la théorie de l&apos;utilité espérée.<lb/> Ces déviations systématiques correspondent une tendance à déformer les probabilités selon<lb/> qu&apos;elles correspondent aux événements rares ou fréquents, ainsi que les enjeux, où on a pu<lb/> montrer une déformation dissymétrique des gains et des pertes. Dans des situations<lb/> concrètes, les perceptions individuelles influencent non seulement les décisions<lb/> individuelles, mais aussi les décisions des pouvoirs publics soumis à l&apos;influence de l&apos;opinion<lb/> ou des élections.<lb/> La déformation des probabilités comporte plusieurs dimensions. Les individus ont tendance à surestimer les écarts vis-à-vis de situations déterministes (les<lb/> probabilités étant dans ce cas dégénérées). Les faibles probabilités (événements rares) sont<lb/> systématiquement surestimées. Il existe une différence fondamentale entre un événement<lb/> impossible (de probabilité rigoureusement nulle, généralement non déformée) et un<lb/> événement possible, mais très peu probable (dont la probabilité sera surestimée).<lb/> Mathématiquement, cette propriété se traduit par une discontinuité de la fonction de<lb/> déformation au voisinage de l&apos;origine.<lb/> Certaines déformations des probabilités de ce type ont été étudiées par de Palma et Picard<lb/> (2008) à l&apos;aide d&apos;une base de données de plus de 4000 individus (par une procédure du type<lb/> « économie expérimentale », menée sur le site http://www.RiskToleranceOnLine.com.<lb/> Les questions proposées pour mettre en évidence ces déformations de probabilité sont du<lb/> type suivant :<lb/> Parmi ces deux possibilités, laquelle préférez-vous ?<lb/> o option A, une loterie (1 000 € avec p = 0.05 et 100 € avec 1-p = 0.95.<lb/> o option B, un gain certain B de 140 €.</figDesc>
        </figure>



    </text>
</tei>

